{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d975ee54-9238-4c20-bf9c-903d4a0f3faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc6ef4d8-f8bb-464a-9771-17f21efd81e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>CabinReduced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass survived                                             name     sex  \\\n",
       "0     1.0        1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1     1.0        1                   Allison, Master. Hudson Trevor    male   \n",
       "2     1.0        0                     Allison, Miss. Helen Loraine  female   \n",
       "3     1.0        0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4     1.0        0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked  boat   body  \\\n",
       "0  29.0000    0.0    0.0   24160  211.3375       B5        S     2    NaN   \n",
       "1   0.9167    1.0    2.0  113781  151.5500  C22 C26        S    11    NaN   \n",
       "2   2.0000    1.0    2.0  113781  151.5500  C22 C26        S  None    NaN   \n",
       "3  30.0000    1.0    2.0  113781  151.5500  C22 C26        S  None  135.0   \n",
       "4  25.0000    1.0    2.0  113781  151.5500  C22 C26        S  None    NaN   \n",
       "\n",
       "                         home.dest CabinReduced  \n",
       "0                     St Louis, MO            B  \n",
       "1  Montreal, PQ / Chesterville, ON            C  \n",
       "2  Montreal, PQ / Chesterville, ON            C  \n",
       "3  Montreal, PQ / Chesterville, ON            C  \n",
       "4  Montreal, PQ / Chesterville, ON            C  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the pickle file from the previous notebook\n",
    "df = pd.read_pickle('df_reduced.pkl')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614ce3b3-60e2-476c-b8e6-1685ebd646ab",
   "metadata": {},
   "source": [
    "The 'train_test_split' function from the 'Scikit Learn' Python library splits arrays or matrices into random train and test subsets.\n",
    "It takes parametres such as:\n",
    "- *arrays - lists/matrices/arrays/dataframes (usually X and y)\n",
    "- test_size - the proportion of the dataset to include in the test split\n",
    "- train_size - the absolute number of train samples (usually test_size is enough)\n",
    "- random_state - a seed value used by the random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41a5d5e-02bb-453f-a0b2-6be11d8baf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex    cabin CabinReduced survived\n",
      "0  female       B5            B        1\n",
      "1    male  C22 C26            C        1\n",
      "2  female  C22 C26            C        0\n",
      "3    male  C22 C26            C        0\n",
      "4  female  C22 C26            C        0\n",
      "5    male      E12            E        1\n",
      "6  female       D7            D        1\n",
      "7    male      A36            A        0\n",
      "8  female     C101            C        1\n",
      "9    male     None            N        0\n"
     ]
    }
   ],
   "source": [
    "# Create a list with three columns - sex, cabin and CabinReduced\n",
    "col_name = ['sex', 'cabin', 'CabinReduced']\n",
    "\n",
    "# Select columns given in the 'col_name' list from the dataframe and set the independent variable\n",
    "X = df[col_name]\n",
    "\n",
    "# Set the dependent variable 0 the 'survived' column\n",
    "y = df['survived']\n",
    "\n",
    "# Print X and y combined in one preview DataFrame\n",
    "preview = X.head(10).copy()\n",
    "preview['survived'] = y.head(10).values\n",
    "print(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ddb89aa-6e21-4601-a675-98217c46d7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (916, 3)\n",
      "X_test shape: (393, 3)\n",
      "y_train shape: (916,)\n",
      "y_test shape: (393,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "# Set the test_size as 30% of all data and the random_state equal to 0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "# Display the dimensions of the datasets\n",
    "datasets = [X_train, X_test, y_train, y_test]\n",
    "names = ['X_train', 'X_test', 'y_train', 'y_test']\n",
    "\n",
    "for name, dataset in zip(names, datasets):\n",
    "    print(f'{name} shape: {dataset.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300e1be-7067-4e25-bd75-59508ab32631",
   "metadata": {},
   "source": [
    "The datasets have the following shapes:\n",
    "- X_train: 916 rows, 3 columns - 916 training samples with 3 features ('sex', 'cabin' and 'CabinReduced')\n",
    "- X_test: 393 rows, 3 columns - 393 test samples with 3 features ('sex', 'cabin' and 'CabinReduced')\n",
    "- y_train: 916 rows, 1 column - 916 labels (whether the person survived)\n",
    "- y_test: 393 rows, 1 column - 393 labels (whether the person survived)\n",
    "\n",
    "X_train and X_test are DataFrames, while y_train and y_test are Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "029cde14-73d9-4830-bba8-545be52999ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"sex\": 0 unique values in test set\n",
      "\"cabin\": 36 unique values in test set\n",
      "\"CabinReduced\": 0 unique values in test set\n"
     ]
    }
   ],
   "source": [
    "# Check the unique labels\n",
    "for col in col_name:\n",
    "    unique_test = [x for x in X_test[col].unique() if x not in X_train[col].unique()]\n",
    "    print(f'\"{col}\": {len(unique_test)} unique values in test set') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc05cb4b-d0ca-467f-8e67-17915a8857e5",
   "metadata": {},
   "source": [
    "For the 'cabin' feature, 36 values appear in the test set but not in the train set. \n",
    "For the 'CabinReduced' and 'sex' features there are no labels that appear in the test set and do not appear in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0906cf44-00c4-401a-a9e6-2110b756d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical values\n",
    "def map_values(col):\n",
    "    values_to_map = pd.concat([X_train[col], X_test[col]]).dropna().unique()\n",
    "    map_dict = {val: i for i, val in enumerate(values_to_map)}\n",
    "    return map_dict\n",
    "\n",
    "# Create mappings\n",
    "cabin_mapped = map_values('cabin')\n",
    "cabin_reduced_mapped = map_values('CabinReduced')\n",
    "sex_mapped = map_values('sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c81f49a-2d21-4f77-a63b-70675368860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the original labels with mapped values\n",
    "X_train['cabin_map'] = X_train['cabin'].map(cabin_mapped)\n",
    "X_test['cabin_map'] = X_test['cabin'].map(cabin_mapped)\n",
    "\n",
    "X_train['CabinReduced_map'] = X_train['CabinReduced'].map(cabin_reduced_mapped)\n",
    "X_test['CabinReduced_map'] = X_test['CabinReduced'].map(cabin_reduced_mapped)\n",
    "\n",
    "X_train['sex_map'] = X_train['sex'].map(sex_mapped)\n",
    "X_test['sex_map'] = X_test['sex'].map(sex_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3be2e70-8ab4-402e-8638-689619415c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in X_train:\n",
      "\n",
      "cabin_map           702\n",
      "CabinReduced_map      0\n",
      "sex_map               0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values in X_test:\n",
      "cabin_map           312\n",
      "CabinReduced_map      0\n",
      "sex_map               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing values\n",
    "print(\"Missing values in X_train:\\n\")\n",
    "print(X_train[['cabin_map', 'CabinReduced_map', 'sex_map']].isnull().sum())\n",
    "\n",
    "print(\"\\n\\nMissing values in X_test:\")\n",
    "print(X_test[['cabin_map', 'CabinReduced_map', 'sex_map']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20e125a7-a509-4fea-babe-ac2f30e04d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with 0\n",
    "X_train[['cabin_map', 'CabinReduced_map', 'sex_map']] = X_train[['cabin_map', 'CabinReduced_map', 'sex_map']].fillna(0)\n",
    "X_test[['cabin_map', 'CabinReduced_map', 'sex_map']] = X_test[['cabin_map', 'CabinReduced_map', 'sex_map']].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bcaecb-51fb-426d-988b-23193bbb04ce",
   "metadata": {},
   "source": [
    "Replacing missing values with 0 is a simple and commonly used solution, but it is not always the best one. In some cases it is better to use, for example, mean or mode imputation, or model-based imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37fc38fa-e4e4-40d5-a560-4f6e1ddeed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Feature  Train Unique  Test Unique\n",
      "0         cabin_map           150           71\n",
      "1  CabinReduced_map             9            8\n",
      "2           sex_map             2            2\n"
     ]
    }
   ],
   "source": [
    "# Compare number of unique values  in test set and train set\n",
    "results = []\n",
    "\n",
    "for col in ['cabin_map', 'CabinReduced_map', 'sex_map']:\n",
    "    train_unique = len(X_train[col].unique())\n",
    "    test_unique = len(X_test[col].unique())\n",
    "    results.append({'Feature': col, 'Train Unique': train_unique, 'Test Unique': test_unique})\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "unique_values_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(unique_values_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a21e6a1-992a-46cb-8250-da21856d1db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Feature  Train (before)  Test (before)  Train (after)  Test (after)\n",
      "0         cabin             151             71            150            71\n",
      "1  CabinReduced               9              8              9             8\n",
      "2           sex               2              2              2             2\n"
     ]
    }
   ],
   "source": [
    " # The train set before mapping\n",
    "before_mapping_train = {\n",
    "    'cabin': len(X_train['cabin'].unique()),\n",
    "    'CabinReduced': len(X_train['CabinReduced'].unique()),\n",
    "    'sex': len(X_train['sex'].unique())\n",
    "}\n",
    "\n",
    "# The test set before mapping\n",
    "before_mapping_test = {\n",
    "    'cabin': len(X_test['cabin'].unique()),\n",
    "    'CabinReduced': len(X_test['CabinReduced'].unique()),\n",
    "    'sex': len(X_test['sex'].unique())\n",
    "}\n",
    "\n",
    "# The train set after mapping\n",
    "after_mapping_train = {\n",
    "    'cabin_map': len(X_train['cabin_map'].unique()),\n",
    "    'CabinReduced_map': len(X_train['CabinReduced_map'].unique()),\n",
    "    'sex_map': len(X_train['sex_map'].unique())\n",
    "}\n",
    "\n",
    "# The test set after mapping\n",
    "after_mapping_test = {\n",
    "    'cabin_map': len(X_test['cabin_map'].unique()),\n",
    "    'CabinReduced_map': len(X_test['CabinReduced_map'].unique()),\n",
    "    'sex_map': len(X_test['sex_map'].unique())\n",
    "}\n",
    "\n",
    "results = [\n",
    "    ['cabin', before_mapping_train['cabin'], before_mapping_test['cabin'], after_mapping_train['cabin_map'], after_mapping_test['cabin_map']],\n",
    "    ['CabinReduced', before_mapping_train['CabinReduced'], before_mapping_test['CabinReduced'], after_mapping_train['CabinReduced_map'], after_mapping_test['CabinReduced_map']],\n",
    "    ['sex', before_mapping_train['sex'], before_mapping_test['sex'], after_mapping_train['sex_map'], after_mapping_test['sex_map']]\n",
    "]\n",
    "\n",
    "# Create the DataFrame\n",
    "unique_values_df = pd.DataFrame(results, columns=['Feature', 'Train (before)', 'Test (before)', 'Train (after)', 'Test (after)'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(unique_values_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f29720-6874-4f67-a612-880eb78d5131",
   "metadata": {},
   "source": [
    "The number of unique values before and after the mapping is mostly consistent, especially for categorical features like sex and CabinReduced.\n",
    "The number of unique values in the test and training sets remains almost identical before and after the transformation, suggesting the data distribution is stable across both sets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DataScience_DL)",
   "language": "python",
   "name": "datascience_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
